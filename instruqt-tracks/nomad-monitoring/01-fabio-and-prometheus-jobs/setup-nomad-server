#!/bin/bash -l

# Uncomment out mapping of 127.0.0.1 to hostname in /etc/hosts and options in /etc/resolv.conf
sed -i "/${HOSTNAME}/d" /etc/hosts
sed -i '/options/d' /etc/resolv.conf

# Some pings to estabish connectivity
ping -c 1 nomad-server
ping -c 1 nomad-client-1
ping -c 1 nomad-client-2
ping -c 1 nomad-client-3

nomad -autocomplete-install

mkdir -p /root/nomad

cd nomad

# Write Consul Server Config
cat <<-EOF > /root/nomad/consul-server.json
{
  "server": true,
  "ui": true,
  "log_level": "INFO",
  "data_dir": "/tmp/consul/server",
  "node_name": "server",
  "bind_addr": "{{ GetInterfaceIP \"ens4\" }}",
  "client_addr": "0.0.0.0",
  "bootstrap_expect": 1
}
EOF

# Run the Consul agent
consul agent -config-file consul-server.json > consul.log 2>&1 &

sleep 15

# Write Nomad Server Config
cat <<-EOF > /root/nomad/nomad-server.hcl
# Setup data dir
data_dir = "/tmp/nomad/server"

# Give the agent a unique name.
name = "server"

# Enable the server
server {
  enabled = true
  bootstrap_expect = 1
}

# Telemetry
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = true
}
EOF

# Run the Nomad server
nomad agent -config nomad-server.hcl > nomad.log 2>&1 &

# Write Nomad Client 1 Config
cat <<-EOF > /root/nomad/nomad-client1.hcl
# Setup data dir
data_dir = "/tmp/nomad/client1"

# Give the agent a unique name.
name = "client1"

# Enable the client
client {
  enabled = true
}

# Telemetry
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = true
}
EOF

# Write Consul Client 1 Config
cat <<-EOF > /root/nomad/consul-client1.json
{
  "ui": true,
  "log_level": "INFO",
  "data_dir": "/tmp/consul/client1",
  "node_name": "client1",
  "bind_addr": "{{ GetInterfaceIP \"ens4\" }}",
  "client_addr": "0.0.0.0",
  "retry_join": [
    "nomad-server"
  ]
}
EOF

# Write Nomad Client 2 Config
cat <<-EOF > /root/nomad/nomad-client2.hcl
# Setup data dir
data_dir = "/tmp/nomad/client2"

# Give the agent a unique name.
name = "client2"

# Enable the client
client {
  enabled = true
}

# Telemetry
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = true
}
EOF

# Write Consul Client 2 Config
cat <<-EOF > /root/nomad/consul-client2.json
{
  "ui": true,
  "log_level": "INFO",
  "data_dir": "/tmp/consul/client2",
  "node_name": "client2",
  "bind_addr": "{{ GetInterfaceIP \"ens4\" }}",
  "client_addr": "0.0.0.0",
  "retry_join": [
    "nomad-server"
  ]
}
EOF

# Write Nomad Client 3 Config
cat <<-EOF > /root/nomad/nomad-client3.hcl
# Setup data dir
data_dir = "/tmp/nomad/client3"

# Give the agent a unique name.
name = "client3"

# Enable the client
client {
  enabled = true
}

# Telemetry
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = true
}
EOF

# Write Consul Client 3 Config
cat <<-EOF > /root/nomad/consul-client3.json
{
  "ui": true,
  "log_level": "INFO",
  "data_dir": "/tmp/consul/client3",
  "node_name": "client3",
  "bind_addr": "{{ GetInterfaceIP \"ens4\" }}",
  "client_addr": "0.0.0.0",
  "retry_join": [
    "nomad-server"
  ]
}
EOF

# Write fabio.nomad
cat <<-EOF > /root/nomad/fabio.nomad
job "fabio" {
  datacenters = ["dc1"]
  type = "system"

  group "fabio" {

    network {
      port "lb" {
        to = 9999
      }
      port "ui" {
        to = 9998
      }
    }

    task "fabio" {
      driver = "docker"
      config {
        image = "fabiolb/fabio"
        network_mode = "host"
      }

      resources {
        cpu    = 100
        memory = 64
      }
    }
  }
}
EOF

# Write first version of prometheus.nomad
cat <<-EOF > /root/nomad/prometheus1.nomad
job "prometheus" {
  datacenters = ["dc1"]
  type = "service"

  group "monitoring" {
    count = 1

    network {
      port "prometheus_ui" {
        to = 9090
      }
    }

    restart {
      attempts = 2
      interval = "30m"
      delay = "15s"
      mode = "fail"
    }
    ephemeral_disk {
      size = 300
    }

    task "prometheus" {
      template {
        change_mode = "noop"
        destination = "local/prometheus.yml"
        data = <<EOH
---
global:
  scrape_interval:     5s
  evaluation_interval: 5s

scrape_configs:

  - job_name: 'nomad_metrics'

    consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['nomad-client', 'nomad']

    relabel_configs:
    - source_labels: ['__meta_consul_tags']
      regex: '(.*)http(.*)'
      action: keep

    scrape_interval: 5s
    metrics_path: /v1/metrics
    params:
      format: ['prometheus']
EOH
      }
      driver = "docker"
      config {
        image = "prom/prometheus:latest"
        volumes = [
          "local/prometheus.yml:/etc/prometheus/prometheus.yml"
        ]
        ports = ["prometheus_ui"]
      }

      service {
        name = "prometheus"
        tags = ["urlprefix-/"]
        port = "prometheus_ui"
        check {
          name     = "prometheus_ui port alive"
          type     = "http"
          path     = "/-/healthy"
          interval = "10s"
          timeout  = "2s"
        }
      }
    }
  }
}
EOF

# Write alertmanager.nomad
cat <<-EOF > /root/nomad/alertmanager.nomad
job "alertmanager" {
  datacenters = ["dc1"]
  type = "service"

  group "alerting" {
    count = 1

    network {
      port "alertmanager_ui" {
        to = 9093
      }
    }

    restart {
      attempts = 2
      interval = "30m"
      delay = "15s"
      mode = "fail"
    }
    ephemeral_disk {
      size = 300
    }

    task "alertmanager" {
      driver = "docker"
      config {
        image = "prom/alertmanager:latest"
        ports = ["alertmanager_ui"]
      }

      service {
        name = "alertmanager"
        tags = ["urlprefix-/alertmanager strip=/alertmanager"]
        port = "alertmanager_ui"
        check {
          name     = "alertmanager_ui port alive"
          type     = "http"
          path     = "/-/healthy"
          interval = "10s"
          timeout  = "2s"
        }
      }
    }
  }
}
EOF

# Write second version of prometheus.nomad
cat <<-EOF > /root/nomad/prometheus2.nomad
job "prometheus" {
  datacenters = ["dc1"]
  type = "service"

  group "monitoring" {
    count = 1

    network {
      port "prometheus_ui" {
        to = 9090
      }
    }

    restart {
      attempts = 2
      interval = "30m"
      delay = "15s"
      mode = "fail"
    }
    ephemeral_disk {
      size = 300
    }

    task "prometheus" {
      template {
        change_mode = "noop"
        destination = "local/webserver_alert.yml"
        data = <<EOH
---
groups:
- name: prometheus_alerts
  rules:
  - alert: Webserver down
    expr: absent(up{job="webserver"})
    for: 10s
    labels:
      severity: critical
    annotations:
      description: "Our webserver is down."
EOH
      }

      template {
        change_mode = "noop"
        destination = "local/prometheus.yml"
        data = <<EOH
---
global:
  scrape_interval:     5s
  evaluation_interval: 5s

alerting:
  alertmanagers:
  - consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['alertmanager']

rule_files:
  - "webserver_alert.yml"

scrape_configs:

  - job_name: 'alertmanager'

    consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['alertmanager']

  - job_name: 'nomad_metrics'

    consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['nomad-client', 'nomad']

    relabel_configs:
    - source_labels: ['__meta_consul_tags']
      regex: '(.*)http(.*)'
      action: keep

    scrape_interval: 5s
    metrics_path: /v1/metrics
    params:
      format: ['prometheus']

  - job_name: 'webserver'

    consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['webserver']

    metrics_path: /metrics
EOH
      }
      driver = "docker"
      config {
        image = "prom/prometheus:latest"
        volumes = [
          "local/webserver_alert.yml:/etc/prometheus/webserver_alert.yml",
          "local/prometheus.yml:/etc/prometheus/prometheus.yml"
        ]
        ports = ["prometheus_ui"]
      }

      service {
        name = "prometheus"
        tags = ["urlprefix-/"]
        port = "prometheus_ui"
        check {
          name     = "prometheus_ui port alive"
          type     = "http"
          path     = "/-/healthy"
          interval = "10s"
          timeout  = "2s"
        }
      }
    }
  }
}
EOF

# Write webserver.nomad
cat <<-EOF > /root/nomad/webserver.nomad
job "webserver" {
  datacenters = ["dc1"]

  group "webserver" {
    network {
      port "http" {}
    }

    task "server" {
      driver = "docker"
      config {
        image = "hashicorp/demo-prometheus-instrumentation:latest"
        ports = ["http"]
      }

      resources {
        cpu = 500
        memory = 256
      }

      service {
        name = "webserver"
        port = "http"

        tags = [
          "testweb",
          "urlprefix-/webserver strip=/webserver",
        ]

        check {
          type     = "http"
          path     = "/"
          interval = "2s"
          timeout  = "2s"
        }
      }
    }
  }
}
EOF

exit 0
